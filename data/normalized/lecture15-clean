Programming Paradigm-Lecturefifteen

Instructor (Jerry Cain):Here we go. He is obviously ready. Welcome. I have three handouts for you today. I put them up on the board because they are not in sequence. I went back and used the No. four Assignment five that I gave out last week, a week ago today. So people who are watching on TV make sure you go back and get the solution to handout nineteen. I think that is what it is. Let me just check, yes, it is indeed. So there is all of these handouts in the last week that have corresponding solution sets, so make sure that you actually download the solutions as well so you can compare your answers to mine and make sure they are in sync with one another. You know you have a midterm on Wednesday evening, it is seven:zerozero to ten:zerozero in Hewitt two hundred. It is a huge room over there; plenty of space as well as the other room, so it will be a great place to hang out for three hours. I want to be clear that I am certainly covering co-generation; you have seen that on the sample exams that I gave out last week. I am not gonna include co-generation for C plus  plus  features, no true references and no object orientation, no methods. So pointers, that is fine, anything related to asterisk, that is real C and I have emphasized that in the early part of the co-generation, but references and methods, the co-generation for that it is not testable in the midterm. You will certainly see it on the final. I always know exactly what type of questions I put on the final for that stuff, but you will not see it this Wednesday. Okay? I also promise to not have any preprocessor or linker or compiler stuff. I went through that kind of as a transition from C figuring out how to build executables from the C language, but I am not gonna test that material because I have tested it in the past and it just never goes well because it is so esoteric and we do not have any kind of real problems to exercise the materials. So people just did not do well, so I just stopped testing it. When I left you last time, I had written this partially simple program that was supposed to model the selling of a one hundred and fifty airline tickets on a single flight. So let me repeat that and point out why it is problematic and how we are gonna move away from it.

I went ahead and did something like this. I wrote it a little bit differently last time, but I will write it like this, num tickets is equal to one hundred and fifty. All I want to do, in this brute force four loop, I will write agent is equal to one agent less than or equal to num agents, agent  plus  plus  - I went ahead and I called this function, called sell tickets, and I am gonna frame in terms of the agent ID num tickets dib, not agents, so that it is planarized in terms of these two values right here, and [inaudible] each ticket agent knows that he or she has to sell that many tickets as part of his or her function call and that is it. That is return zero to satisfy the compiler. Okay. We are not gonna allow anything to go wrong in this simple program. The implementation of sell tickets - it is not gonna be rocket science. I am gonna write it a little bit differently than I would traditionally write because I am paying forward to the way we are gonna change the example to in a second. Void sell tickets, int agent ID, int num ticks to sell, and even though it is a little weird, let me not use a four loop, let me use a wild loop. Wild loop is the case that num tickets to sell is greater than zero - go ahead and do print F agent percent V sells a ticket. Agent number and then does num tickets to sell minus minus, finally, my arms tired, but I am gonna keep on writing, print F agent percent D all done. Agent num - this arms gonna be bigger than the other one by the end of lecture. Okay. There we go. From a code standpoint, it is moronically simple. I am not trying to revisit four loops and wild loops. What I am more interested in doing is figuring out why this is as simulation is really not all that good in the sense that it is not really modeling what would truly happen.

The way this is set up, and I am speaking as this is new material, but it is not, it is clearly gonna be sequential and ticket agent one is gonna sell all of his or her fifteen tickets before anything happens with ticket agent two. So you know that the print out of this would have a one hundred and sixty lines, sixteen lines per ticket agent - okay, I am sorry, yeah, sixteen lines per ticket agent, but they would be sorted all ticket agent number one followed by an all done comment, that is the sixteenth. Okay. Does that make sense to people? Okay. I am sorry, one hundred and sixty-five because there is fifteen agents going on here - no, I am sorry, there is ten agents so that is one hundred and sixty. I am just confused, but everything is gonna be all about agent number one before it is agent number two, before it is agent number three, etcetera. I really do not like that. Okay? This is a fairly compelling example where if we are really trying to model the simulation of an actual airline ticketing room that you want to see all of these ticket agents running simultaneously and working, not competing, but working collaboratively to sell all one hundred and fifty tickets at the same time. Now, what I am gonna do is I am gonna repeat the four loop, int agent, agent, less than or equal to the agents, agent  plus  plus . Here is how you set up the actual dogs at the racetrack. What I want to do is I want to create a name that is unique to a particular ticket agent. I am gonna do that by declaring this in place buffer - you have not seen this function, it is not the emphasis, but I might as well show it to you cause it is in the handout. I am gonna print F, not to the console, but to a character buffer, there is a function called S print off to do that rather than actually echoing the characters to the screen, I echo the characters in place to a character array and make sure it turns out to be a C string.

The place where they function as that console of sorts begins at the name address, okay, and as long as I do not print more than thirty-two characters I will not overrun the boundaries of this thing. This is the structure of what gets printed and then I will fill in agent. So for all intensive purposes, on the zero generation or the first generation of this thing, after that S print off call is made, name contains - it goes from garbage to the C string, agent one thread. The reason I do that is because I want to call this function called thread new and the name actually serves as the name of the thread and it is also helpful for debugging purposes should you be passing a true to that thread package. And then you go ahead and you pass the address of the function that you would like to execute in a single thread of execution. Okay. This right here is just an arbitrary function pointer. All of the arguments have to be four bi arguments with just the constrain of the system so you can pass ints and floats and pointers, but you cannot throw in struts or characters or shorts, it will confuse the system. You have to tell it how many arguments are expected of this particular function. We are gonna have scenarios where the thread functions do not need to take any arguments. We are gonna have a scenario like we have right here where sell tickets takes two of them. Beyond the two, you pass in the numbers that are of interest, so agent and num tickets divided buy num agents. Now, this does not actually prompt sell tickets to start executing. All it does is it lines it up at a gate.

Student:[Inaudible]

Instructor (Jerry Cain):The prototype of thread new just requires a thread name right here. We have to do it because it is [inaudible] but that is a lame answer. You really do want something available to you to identify a particular thread, that for instance, is failing you during the debugging process, and if you have fifteen of these things, does that make sense? I am sorry, you have ten of these things and then one of them is falling or one of them is never exiting, which is actually a common thing we will see in multi-threading. You want to be able to know which of the threads is not exiting so you can go and look at the particular implementation of that function. Okay.

Okay. So, procedurally, what happens up front, as we say, we are using threads and then you lay down gates one through ten, all of these things that are gonna follow, the sell tickets recipe, that is what they need to follow in order to run from the starting gate to the finish line and then this basically sounds the bell, fires the gun. Okay. This is a function block until all of these threads actually finish and run a completion and then when all ten threads are finished, this returns and it passes on to what will be the end of the entire function.

Student:If I wanted to do the same process somewhere else, is this the int package and run all threads within the scope of the function?

Instructor (Jerry Cain):It actually does not have to be in main, it is just most conveniently put there.

Student:[Inaudible] as well when [inaudible] everything out there?

Instructor (Jerry Cain):What has to happen is that before you call run all threads you have to call the package just exactly once and you have to set up all the threads, whether it is directly in main or through sub functions to set up all of the dogs. Okay. Does that make sense? This actually fires the gun and tells all the threads to start running. It turns out that as threads execute, as part of their implementation, they can themselves call thread new. Does that make sense? The threads themselves can spawn their own child threads, okay, grandchildren threads, whatever you want to you. The ridiculous metaphor I have is that somehow while a dog is in the race it gives birth to three new babies and throws them back to the beginning of the gate, okay, and say is, "Please run," and sometimes there is interesting concurrency issues that can come up with that type of thing, but I will actually get to that with a more advanced example probably Wednesday or Friday.

Student:[Inaudible]

Instructor (Jerry Cain):This just basically says now we are in thread mode. Okay. Once this has been called all threads that are ever created in the process, even if they are children threads, just are not executing immediately. Okay. So as far as this is concerned, I want to just invent a function right here. If random chance, zero.one, I want to call a thread sleep function and I will just pass in and say one,zerozerozero. Okay. That thread sleep basically says that as part of execution if a thread is running and it executes the thread sleep function that it pulls itself off the processor for at least, in this case, a second, that number that passes as an argument is expressed in milliseconds. So this means that every time it flips a biased coin and it comes up heads with probability of ten percent or .one, rather, it will force it to halt. Now, that is not the only way a thread will halt, but this is a way for you to problematically tell a thread to stop running. Let is forget about thread sleep. I should not have talked about that yet. What actually happens is that when you spawn off two or more threads, even technically one child thread, but two or more is when it is interesting, run all threads establishes something of a heartbeat.

In between the top of every single finger some different function, usually in a round robin fashion, but not necessarily, gets the time slice that exists in between the two finger taps. Does that make sense? So it is, like, agent one, agent two runs, agent three runs, agent four runs, in that round robin manner, okay, and however much progress they happen to make in that time slice is the progress they make. Now, if I do not introduce any randomization it is probably the case that on a real system it would execute the same exact number of assembly code instructions. Okay. Or very close to it so everyone would make exactly the same amount of partial progress with each time slice. Okay. Does that make sense? To make it a little bit more real world, we introduce some [inaudible] process here where things all of a sudden get a little bit random and maybe it is the case that ticket agent one sells two tickets and it is in his or her time slice and then gets pulled off the processor instead of actually being allowed to sell two more tickets. Maybe ticket agent two comes next and sells four tickets; maybe ticket agent three comes next and sells four tickets because this coin flip never comes up heads. Does that make sense to people? Yep.

Student:[Inaudible], which threads [inaudible]?

Instructor (Jerry Cain):Well, the one that is executed. The one that actually calls it. Okay. I mean, it is only called once, but the ten dogs up there are actually each following this recipe, they each have their own little pointer in to be an assembly code that this compiled to. Okay. And if they happen to jump into this function right here then the thread that is actually is stuck inside that function is pulled off the processor and it is even pulled off what is called the Ready Q and put on this thing called the Blocked Q until this number of milliseconds, in terms of time, elapses. Does that make sense? Yep.

Student:[Inaudible] or run all threads, is there any control over how many [inaudible] cycles each one will get?

Instructor (Jerry Cain):Not in our system. Some very sophisticated thread libraries, I do not want to say very sophisticated, a lot of thread libraries, they do not always give you control over the amount of time that is in a time slice. They do want that to be somewhat regular because they do not want you to have unpredictable results, certainly not during the development process. Even though ours does not, some thread libraries, particularly the one in Java, everybody will be the most familiar with by the end of next year when you take one hundred and eight, you learn about the thread library there. You can attach priorities. There is only three degrees of priorities in Java. I am sorry, that is not true - there is ten levels of priorities in Java where you can assign a priority of one to ten and then, usually, it is the case that they are all sorted and all the threads with priority ten execute and run to completion before anything with priority nine is given time. Okay. But we do not have any of that here. We really just want to think of all threads as equally likely to get the processor for a particular time slice in this round robin manner unless there are other things in place that actually block it from being able to make process.

Okay. So think about this line as basically really not blocking it all or blocking for an arbitrary amount of time. Okay. What I want you to imagine here is what type of print out you might actually get in response to this thread implementation. You might get three print Fs, agent one sells a ticket, it may happen like that. Maybe it sells three, maybe agent two comes next, maybe agent three sells five because that is how much time slice allows, maybe five is actually the most you would actually see as the number of tickets that sold. But you understand what I am getting at here. Does that make sense? It would just keep on cycling through all of them. Maybe it is the case after one hundred and thirty or so lines that, for whatever reason, agent seven all done gets printed and then maybe it is the case that agent eight sells a ticket, agent eight all done and then eventually maybe it is the case, for whatever reason, agent four is the last one to sell a ticket and this is just representative of the type of output you might see from this. Now, there is nothing interesting about this from a simulation standpoint because there is really no compelling reason; from a performance stand point to use threading here except that you are trying to emulate the real world a little bit more. There are situations that you want to go with threading for performance reasons, this is not one of them. I am just trying to illustrate the thread package. Yep.

Student:If you did not do the thread sleeve, would you see agent one sells a ticket, agent one sells a ticket, agent one sells a ticket or is it agent one sells a ticket, agent two sells a ticket?

Instructor (Jerry Cain):You would actually see - the thread library has no notion of what a wild loop is so it is not like it detects it, you jump back and uses that as a signal to pull it off the processor. Let is say that the typical time slice is one hundred milliseconds, however many tickets can get sold in a one hundred milliseconds is how many would be published. Sometimes it is gonna be partial, maybe you are gonna be halfway through the implementation of a call to print F, right, when it gets pulled off a processor and then when it gets the processor back it continues through the partial execution of print out to complete it, return and decrement the num tickets to sell count. Okay. Does that make sense?

Student:There is no way to [inaudible] two processes that you want to run parallel, but you want them to switch back and forth faster than one hundred milliseconds?

Instructor (Jerry Cain):You can. Well, [inaudible] you certainly do not have that. I have to think that there is some thread packages out there that do allow you to control the time slice. It is usually not that high priority. Usually you do not introduce threading into a program to have control over the time slicing, you really just do it to have concurrency in the first place, let the thread manager figure out which thread is gonna make the most progress. In an ideal world, we actually do not want to pull agent one off the processor at all if agents two through ten are on extremely long phone conversations, and that does not happen here, but in a real simulation, you might want agent one to keep on selling tickets if all the others are blocked from something else. Okay. This is just in place to illustrate the thread new and the run all the threads and the initial [inaudible] concept. Okay. Yep.

Student:[Inaudible] does not [inaudible], it just sort of pulls that one off the Q and it keeps running?

Instructor (Jerry Cain):That is right. And you have to think that this is actually being called by ten different threads in this set up. It is only written once. It is, basically, like ten copies of the same book, but it is not even that. It' actually ten copies of the same webpage and the webpage itself is hosted on one machine. Okay. Does that make sense? There is one copy of the code, ten independent threads are following the same recipe. Okay.

Student:Well, and [inaudible] run threads directly after any initial thread package?

Instructor (Jerry Cain):Well, it has to be called - oh, I see what you are saying. In other words, to set this up and maybe call it right there -

Student:Yeah.

Instructor (Jerry Cain):- with the idea that these actually run immediately, I know what you are doing. In our system, it would not work because this is a function blocks until all threads have been completed. So what would happen is you could it an int thread package, you would call one whole thread, but there would not be any, so it would return and then it would go on and spawn these threads that are not allowed to run because run all threads is actually a return.

Student:Okay.

Instructor (Jerry Cain):Okay. This is just idiomatic. Do this, set up at least one thread to run to make sure that all the work that needs to get done gets done, but in this concurrent manner as opposed to this sequential manner, and then call that just to fire the gun. Okay. Yep.

Student:What happens to all sell tickets as that whole thread contacts [inaudible] thread [inaudible] command?

Instructor (Jerry Cain):It is not inside a thread?

Student:Right.

Instructor (Jerry Cain):It could work. The way that the thread library works, the main thread is also a thread, so as part of as sequential execution, it is really not sequential. It happens to still be in a thread, it just happens to be the main thread as opposed to one of these child threads that is spawned off by what was reachable for main. Now, I have to say I have never tested that because I have never given an assignment or done an example where I exercised the edges of the thread library, I have just kind of gone with the way it was designed to be just so I can make progress. But you could try it when the assignment goes out and see what happens with it. You will never see a meaningful example from me that actually will realize that. Yep.

Student:You said the thread does not know if it is in a wild loop, does it know if it is in an instruction, like, does it know that [inaudible] and then the time went off, is it -

Instructor (Jerry Cain):Right. Right. That is certainly the most interesting part of today is lecture is that right now, you know enough about co-generation, I am hoping, because you are gonna be tested on it in two days, what we say is that it is not an atomic operation. It looks like it is atomic because it is written in one statement right here, but what happens is that this really corresponds to probably what we would as a local variable, it would be a three-assembly code statement. Does that make sense to people? So it is gonna basically load num tickets to sell and do a registered decrement it by one and flush it back out. This is going to be a complexity that we start to solve in the last twenty minutes of lecture right here. So when it gets swapped off a processor, it could be right before the first instruction of the three that this compiles to. It could actually finish right after the third of the three, or it could be pulled off the processor thirty-three percent or sixty-six.seven percent of the way through the code block that this compiles to. Does that make sense? You feel every single stall time in sequence. If you use threading, and this is the best example of all of the one that I am gonna have, I think threading is really important. If you use threading and you spawn off twelve download from BBC server threads, all of them make enough progress, all of them try to open the connect and because that is considered a block at the kernel level, it is pulled off the processor. It is a much more harsh version of thread sleep. But it sleeps for a meaningful reason because it really can make a good progress and the thread realizes that and the thread manager realizes that so it pulls it off a processor while it is waiting for the connection to be established. Does that make sense? Well, imagine that all happening with twelve threads, all of those dead times that are associated with the network connection, they all align and overlap and pipeline in this way that really saves us a lot of time. Does that make sense? Okay. Yep. Go ahead.

Student:The last lecture you mentioned about downloading strings in class; I was thinking if you only have download capacity, you only have so much speed you can download, so what size files can you download in a certain amount of time, how can you download more than that?

Instructor (Jerry Cain):You are actually not. As far as the downloading is concerned, if you are dealing with a unit processor and you are dealing with one processor with one ram and one core, then you are dealing, primarily, only with the ability to index one article at a time as the text comes through. So you are right, you do not save time for the actual pulling of the text and parsing of it, and updating your hash sets, but you really save the time with your network connections, and that is what the huge win is. Okay. Does that make sense? Okay.

So what I want to do here is I want to complicate this problem a little bit, but complicate it in a meaningful way. In a real world simulation, it might be the case that you have two ticket agents, and you have to sell ten more tickets and if somebody is stuck on the phone because they want to buy the ticket or not, so the other ticket agent should be able to sell all nine or ten tickets while the other is blocked with some time consuming customer. So what I would rather do is rather than actual instructing each particular thread to sell a pre-determined number of tickets, I would rather grant them all access to the same shared integer, the master variable, that stores the number of remaining tickets and do something like this; int agent and int star numb tickets and I will put a P there. I will close it off for the moment. I will change this up here in a second. What I want to do is I want each agent to know what their badge number is, but I also want them to be able to go back to the main function and find the master copy of the number of variables that are remaining. This is basically the equivalent of the one master copy of your checking account balance. Every single ATM machine in the world is supposed to have atomic transactional access to. Does that make sense to people? Okay. Here is the main thread and its stack frame. All ten other stack frames for the ten other executing threads all have pointers to that one one hundred and fifty inside, and that is how they kind of keep dibs on how many tickets there are remaining to sell. Okay. Does that make sense? Now, the problem and this is actually not even the full problem, but I will simplify the problem to make it seem like it is easily solved, is that I, as ticket agent one, might come through and I might commit to that test and say, "Oh, wow, there is, in fact, one ticket left, that is greater than zero, so I am gonna commit to selling it."

Make sense? And then boo-hoo, it gets swapped off the processor right after the curly [inaudible], but before anything associated with the num tickets minus minus. Okay. Make sense? So it gets swapped off the processor and thread number two comes in and executes the same test. "Oh, look, there is one ticket left, I am gonna sell it," and it comes in and it commits to trying to sell it, but it gets swapped off the processor. Same thing for thread three, thread four, it could be this diabolical situation where everybody is really excited to sell the one remaining ticket. They do not go back and recheck the test after they get the processor back, that is not what is probability encoded, so they are all gonna try and decrement this shared global and so one, could, potentially, go down to negative nine. I do not think this is why airlines overbook flights, okay? But you can understand the type of concurrency problem that exists here. They are all depending on the same shared piece of data, and if they are not careful in the way they manage the shared data and if it is partway through the execution and it makes decisions based on information that will become immediately stale if its pulled off the processor then the integrity of the global data can actually be mucked with and be compromised. So, at the very least, we want this all the way through that to, more or less, be executed in full. Okay. So basically what that top bracket and what the bottom bracket does it kind of marks that thing right there, is what is called a critical region. It is, like, once I enter this region, no one else is supposed to be in here while I am doing surgery on that global variable. Does that make sense? Now, there is nothing in the code that actually says, "Please other threads, do not come in here because I am," there have to be some directives that are put in place to block out other threads. This is the situation where you are really glad that the bathroom door locks because if you are in there, you do not want them to have the privilege of just walking in because they are running in their own little thread. You actually have to have a directive in place, this thing called a lock, I am gonna frame it as a binary lock, I think for obvious reasons, because you only want one person in the bathroom or in the critical region, right here, at any one moment. Okay.

So what I want to do is I want to talk about the most common concurrency tool that is in place to actually help delineate what is considered to be a critical region. It involves me introducing another variable type. I want to introduce something called a semaphore, and I am gonna call it lock and I am gonna set it equal to semaphore new. It takes two arguments; the first one I do not care about, the first one is gonna be some integer. Now, I am just introducing semaphore like it is a word that you are all familiar with. I know you probably know what semaphore means in a general sense, but in a programming sense what a semaphore really functions as is non-negative integer, at least in our library it is considered to be a non-negative integer, that as a data type has functionality that supports atomic plus plus and atomic minus minus. This, basically, sets this glorified integer equal to one, okay, the minus minus and the plus plus against this lock, comes in the form of two different functions. There is a function called semaphore weight which, in this case, would take the lock variable. There is also another function called semaphore signal, which also takes the semaphore. Now, those are functions that, behind the scenes, emulate minus minus and plus plus, but they just figure out using special hardware or special instructions of the assembly code language to actually take the integer that is wrapped around by the semaphore, in this case, what is initially a one, and provide atomic minus minus. Okay. So, in other words, this right here would be decremented to zero if this were called against it. This would promote it back up to one. The reason that weight is the verb here is because we are gonna generalize a little bit. Think about the semaphore as tracking a resource. In this case, there is exactly one person allowed in the bathroom or there is one person allowed into the critical region, okay, which is why that is a one in the first place and you acquire that resource or you wait for that resource to be available and when you do not need it anymore, you signal it or you somehow release the lock. There is one key that I forgot to make - is that because the semaphore integers in our world are never allowed to go from non-negative to negative, there is a one special scenario that is handled by semaphore weight. If a semaphore weight is passed to semaphore, that at the moment, it analyzes it and is surrounding a zero, it does not decrement it to negative one; it is not allowed to do that. That is just the definition of what a semaphore is. If it detects that it is a zero, it actually does what is called block and it blocks on that semaphore.

It actually pulls itself off the processor because it knows that it is obviously waiting, presumably for some other thread to signal that thing before it could ever pass through that semaphore weight [inaudible]. Does that make sense to people? Okay. Basically, if I am jiggling the door for the bathroom, like we always do at restaurants to wonder whether somebody is really in there or not, okay, you need, before you can really pass in there, you need someone else to release the lock, some other thread or some other agent in the form of a semaphore signal call before you really can go and open that door and then you can look it yourself. What I want to do is I want to do is pass in three arguments to sell tickets. The reason I want to do that is because I want to tell the ticket agent what his or her idea is. I want to pass in the address of the shared resource, but I also want to pass in this thing I called lock. Now, the semaphore type is actually a pointer to an incomplete type. It is not copies, it is actually share some kind of strut behind the scenes that tracks the integer inside of it. And then the prototype of this would be the change to take a semaphore, I will call lock, and this is the implementation I want to go with. I am gonna simplify it a little bit. I am gonna say while true, I am gonna semaphore weight for the lock. As a thread, I have no business following that pointer and looking at its value and comparing it, using it in any sense, even comparing it to zero, because as I advance through the execution, I cannot trust that that comparison is actually meaningful, if at any point during progression, it actually gets swapped off the processor and other threads can go and muck with that shared variable. Does that make sense to people? Okay. So what I want to do is I want to wait on the locked bathroom door and if I happen to be the one that first detects that it is unlocked and I can go in and, in this atomic manner, actually do a decrement. So as I detect that it is been promoted from zero to one, I actually take it from one down to zero and actually pass through this semaphore weight call, then I can do this. Num tickets P is double equal to zero then I want to break, otherwise, I want to do this - I want to print up that I have right here to say that I sold a ticket and then I want to semaphore the signal lock. The one thing I want to do here is that if, as a thread, I acquire the lock and I notice that there are no more tickets to be sold, when I break out I do not want to forever hold the lock on the bathroom. Okay. If you can programmatically unlock the door from afar you are no longer in the critical region, but you still somehow manage to unlock the bathroom door. Now, there is a couple of points I can make about this just to let it rest for you because this is probably where I am gonna leave things until Wednesday. I initialize the semaphore to one up there.

That basically functions as a true. It basically says that the resource is available to exactly one thread and the first thread to get here actually does manage to, in an atomic way, take the one and do a minus minus on a down to zero because it actually committed to the minus minus, it returns - it executes this. It takes the zero back to a one one. It may come back around and take the one back down to a zero, but it is always, like, lock, unlock, lock, unlock, lock, and maybe it actually gets swapped off the processor right here. That would normally be dangerous except that it is leaving the semaphore in a state that it surrounds a zero. Okay. So there is some other threads that the processor and it certainly will then they come here and they, basically, are blocked by a zero semaphore. Does that make sense? Okay. Imagine a scenario where I accidentally - and this is actually the type of thing you have to be careful about because it is so easy to type a zero versus a one when you are typing a lot of them. If I do that right there, this creates a situation that you really have to be worried about when you are dealing with concurrency and threads, is that if I accidentally lock the bathroom door before anyone comes to the party, everybody is' gonna be blocked and no one is in a position to actually unlock it. At least not the way I have coded things up right here. Does that make sense? If I make the mistake of putting a zero up there, then every single thread will get this far and they are all gonna be thinking that someone else is gonna be [inaudible] that semaphore, so all ten of them are pulled off the processor and everybody is just waiting. That is not the case because of that one little bug that I put up there. Okay. Make sense? If I have the opposite error and I do that right there, from a programmatic standpoint, if it is gonna be two, it might as well be ten. If you are gonna let two people in the bathroom why not let all ten? If you are gonna actually let two people go into the critical region and muck with global data at the same time, then you have the potential for having two threads deal with a shared global variable in a way that they really cannot trust each other. Does that make sense to people?

Student:Yeah.

Instructor (Jerry Cain):Okay. So there is that. So the real answer here is that this, in this particular case, should be a one. Now, we will see situations where a zero is the right value. Okay. We will see situations where two or five or eight or twenty or sixty-four are the right values, but for this one scenario where I am using a semaphore to basically limit access to what is clearly identified as a critical region, okay, that is the common pattern for using a semaphore. Okay. Question right there?

Student:Do you have two signal locks?

Instructor (Jerry Cain):Two signal locks, oh, this one right here? This is the one that actually is there whenever I actually do do a decrement. Because I can break out of the loop right here - if I break out of the loop, I circumvent this final call right here, but other threads may be blocks on the semaphore right here. All they need to do is to verify, as well, that there are no tickets left, but you still have to allow them to program as they get there so they as threads can also exit. Okay. Does that make sense? Okay. Yep.

Student:Is there something stronger than a semaphore that actually will not let the thread get pulled if you have something time sensitive?

Instructor (Jerry Cain):Actually, just priorities is really it. Even then, it is probably up to the thread manager as to whether or not - what would probably happen is a really sophisticated thread manager might actually know behind the scenes before it even grants the thread or processor, but there is only one thread with that priority. So it might actually have - and I do not know that this is the case and I am just speaking in terms of implementation details - it might say, "Okay, that is the only one of that high priority, so unless we see a spawn of thread of equal priority or higher priority, we are just gonna let it run until it actually blocks itself," in which case, we do not have any choice. I do not know that many systems do that. It is technically possible to do it. Okay. So we will have more examples come Wednesday, but I just wanted to make sure that you all got this. Have a good night.

[End of Audio]

Duration: fifty-three Minutes



